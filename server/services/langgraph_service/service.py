from typing import Optional, List, Dict, Any, cast, Set
from models.config_model import ModelInfo
from services.db_service import db_service
from services.config_service import config_service
from services.websocket_service import send_to_websocket  # type: ignore
from langchain_ollama import ChatOllama
from langchain_openai import ChatOpenAI
from langgraph_swarm import create_swarm  # type: ignore
from utils.http_client import HttpClient

import traceback

from .agent_manager import AgentManager
from .handlers import StreamProcessor


def _fix_chat_history(messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ä¿®å¤èŠå¤©å†å²ä¸­ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨

    æ ¹æ®LangGraphæ–‡æ¡£å»ºè®®ï¼Œç§»é™¤æ²¡æœ‰å¯¹åº”ToolMessageçš„tool_calls
    å‚è€ƒ: https://langchain-ai.github.io/langgraph/troubleshooting/errors/INVALID_CHAT_HISTORY/
    """
    if not messages:
        return messages

    fixed_messages: List[Dict[str, Any]] = []
    tool_call_ids: Set[str] = set()

    # ç¬¬ä¸€éï¼šæ”¶é›†æ‰€æœ‰ToolMessageçš„tool_call_id
    for msg in messages:
        if msg.get('role') == 'tool' and msg.get('tool_call_id'):
            tool_call_id = msg.get('tool_call_id')
            if tool_call_id:
                tool_call_ids.add(tool_call_id)

    # ç¬¬äºŒéï¼šä¿®å¤AIMessageä¸­çš„tool_calls
    for msg in messages:
        if msg.get('role') == 'assistant' and msg.get('tool_calls'):
            # è¿‡æ»¤æ‰æ²¡æœ‰å¯¹åº”ToolMessageçš„tool_calls
            valid_tool_calls: List[Dict[str, Any]] = []
            removed_calls: List[str] = []

            for tool_call in msg.get('tool_calls', []):
                tool_call_id = tool_call.get('id')
                if tool_call_id in tool_call_ids:
                    valid_tool_calls.append(tool_call)
                elif tool_call_id:
                    removed_calls.append(tool_call_id)

            # è®°å½•ä¿®å¤ä¿¡æ¯
            if removed_calls:
                print(
                    f"ğŸ”§ ä¿®å¤æ¶ˆæ¯å†å²ï¼šç§»é™¤äº† {len(removed_calls)} ä¸ªä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨: {removed_calls}")

            # æ›´æ–°æ¶ˆæ¯
            if valid_tool_calls:
                msg_copy = msg.copy()
                msg_copy['tool_calls'] = valid_tool_calls
                fixed_messages.append(msg_copy)
            elif msg.get('content'):  # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„tool_callsä½†æœ‰contentï¼Œä¿ç•™æ¶ˆæ¯
                msg_copy = msg.copy()
                msg_copy.pop('tool_calls', None)  # ç§»é™¤ç©ºçš„tool_calls
                fixed_messages.append(msg_copy)
            # å¦‚æœæ—¢æ²¡æœ‰æœ‰æ•ˆtool_callsä¹Ÿæ²¡æœ‰contentï¼Œè·³è¿‡è¿™æ¡æ¶ˆæ¯
        else:
            # éassistantæ¶ˆæ¯æˆ–æ²¡æœ‰tool_callsçš„æ¶ˆæ¯ç›´æ¥ä¿ç•™
            fixed_messages.append(msg)

    return fixed_messages


async def langgraph_multi_agent(
    messages: List[Dict[str, Any]],
    canvas_id: str,
    session_id: str,
    text_model: ModelInfo,
    media_model: ModelInfo,  # æ›´åä¸ºmedia_modelï¼Œæ”¯æŒå›¾åƒå’Œè§†é¢‘æ¨¡å‹
    system_prompt: Optional[str] = None
) -> None:
    """å¤šæ™ºèƒ½ä½“å¤„ç†å‡½æ•°

    Args:
        messages: æ¶ˆæ¯å†å²
        canvas_id: ç”»å¸ƒID
        session_id: ä¼šè¯ID
        text_model: æ–‡æœ¬æ¨¡å‹é…ç½®
        media_model: åª’ä½“æ¨¡å‹é…ç½®ï¼ˆå›¾åƒæˆ–è§†é¢‘æ¨¡å‹ï¼‰
        system_prompt: ç³»ç»Ÿæç¤ºè¯
    """
    try:
        # 0. ä¿®å¤æ¶ˆæ¯å†å²
        fixed_messages = _fix_chat_history(messages)

        # 1. æ¨¡å‹é…ç½®
        model = _create_model(text_model)
        tool_name = _determine_tool_name(
            media_model, text_model.get('provider'))

        # 2. åˆ›å»ºæ™ºèƒ½ä½“
        agents = AgentManager.create_agents(
            model, tool_name, system_prompt or "")
        agent_names = ['planner', 'image_video_creator',
                       'image_designer', 'video_designer']
        last_agent = AgentManager.get_last_active_agent(
            fixed_messages, agent_names)

        print('ğŸ‘‡last_agent', last_agent)

        # 3. åˆ›å»ºæ™ºèƒ½ä½“ç¾¤ç»„
        swarm = create_swarm(
            agents=agents,
            default_active_agent=last_agent if last_agent else agent_names[0]
        ).compile()  # type: ignore

        # 4. åˆ›å»ºä¸Šä¸‹æ–‡
        context = _create_context(canvas_id, session_id, media_model)

        # 5. æµå¤„ç†
        processor = StreamProcessor(
            session_id, db_service, send_to_websocket)  # type: ignore
        await processor.process_stream(swarm, fixed_messages, context)

    except Exception as e:
        await _handle_error(e, session_id)


def _create_model(text_model: ModelInfo) -> Any:
    """åˆ›å»ºè¯­è¨€æ¨¡å‹å®ä¾‹"""
    model = text_model.get('model')
    provider = text_model.get('provider')
    url = text_model.get('url')
    api_key = config_service.app_config.get(  # type: ignore
        provider, {}).get("api_key", "")

    # TODO: Verify if max token is working
    # max_tokens = text_model.get('max_tokens', 8148)

    if provider == 'ollama':
        return ChatOllama(
            model=model,
            base_url=url,
        )
    else:
        # Create httpx client with SSL configuration for ChatOpenAI
        http_client = HttpClient.create_sync_client(timeout=15)
        http_async_client = HttpClient.create_async_client(timeout=15)
        return ChatOpenAI(
            model=model,
            api_key=api_key,  # type: ignore
            timeout=15,
            base_url=url,
            temperature=0,
            # max_tokens=max_tokens, # TODO: æš‚æ—¶æ³¨é‡Šæ‰æœ‰é—®é¢˜çš„å‚æ•°
            http_client=http_client,
            http_async_client=http_async_client
        )


def _determine_tool_name(media_model: ModelInfo, provider: str) -> str:
    """ç¡®å®šå·¥å…·åç§°ï¼ˆæ”¯æŒå›¾åƒå’Œè§†é¢‘æ¨¡å‹ï¼‰"""
    model_name = media_model.get('model', '')
    model_type = media_model.get('type', '')

    # è§†é¢‘æ¨¡å‹å·¥å…·é€‰æ‹©
    if model_type == 'video':
        if model_name in ['doubao-seedance-1-0-pro-250528']:
            return 'generate_video_doubao_seedance_1_0_pro'
        # å…¶ä»–è§†é¢‘æ¨¡å‹å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        return 'generate_video'  # é»˜è®¤è§†é¢‘å·¥å…·

    # å›¾åƒæ¨¡å‹å·¥å…·é€‰æ‹©ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
    tool_name = 'generate_image'
    is_jaaz_gpt_model = model_name.startswith('openai') and provider == 'jaaz'
    if is_jaaz_gpt_model:
        tool_name = 'generate_image_by_gpt'
    if media_model.get('type') == 'tool':
        tool_name = media_model.get('model')

    return tool_name


def _create_context(canvas_id: str, session_id: str, media_model: ModelInfo) -> Dict[str, Any]:
    """åˆ›å»ºä¸Šä¸‹æ–‡ä¿¡æ¯"""
    model_info = {
        'image': media_model,  # ä¿æŒå‘åå…¼å®¹ï¼Œè¿™é‡Œä»ä½¿ç”¨'image'é”®å
    }

    return {
        'canvas_id': canvas_id,
        'session_id': session_id,
        'model_info': model_info,
    }


async def _handle_error(error: Exception, session_id: str) -> None:
    """å¤„ç†é”™è¯¯"""
    print('Error in langgraph_agent', error)
    tb_str = traceback.format_exc()
    print(f"Full traceback:\n{tb_str}")
    traceback.print_exc()

    await send_to_websocket(session_id, cast(Dict[str, Any], {
        'type': 'error',
        'error': str(error)
    }))
